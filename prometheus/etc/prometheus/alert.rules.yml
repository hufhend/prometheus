groups:
  - name: "prometheus"
    rules:
      - alert: ExporterDown
        expr: up == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Exporter down (instance {{ $labels.instance }})"
          description: "Prometheus exporter down\n  VALUE = {{ $value }}\n  LABELS: Component {{ $labels.instance }} from {{ $labels.job }}"

      - alert: NginxHighHttp5xxErrorRate
        expr: rate(nginx_http_response_count_total{env!="develop", status=~"5[0-9]*"}[1m])  > 5
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: Nginx high HTTP 5xx error rate (instance {{ $labels.exported_instance }})
          description: "Too many HTTP requests with status 5xx (> 5)\n  VALUE = {{ $value }}\n  LABELS = App {{ $labels.app }} in {{ $labels.env }} on {{ $labels.host }} method {{ $labels.method }} status {{ $labels.status }}"

# 4xx status are not evaluated, can be used for debugging
#      - alert: NginxHighHttp4xxErrorRate
#        expr: rate(nginx_http_response_count_total{env!="develop", status=~"4[0-9]*"}[1m])  > 5
#        for: 2m
#        labels:
#          severity: critical
#        annotations:
#          summary: Nginx high HTTP 4xx error rate (instance {{ $labels.exported_instance }})
#          description: "Too many HTTP requests with status 4xx (> 5)\n  VALUE = {{ $value }}\n  LABELS = App {{ $labels.app }} in {{ $labels.env }} on {{ $labels.host }} method {{ $labels.method }} status {{ $labels.status }}"

      - alert: NginxLatencyHigh
        expr: rate(nginx_http_response_time_seconds{env!="develop",quantile="0.99",status=~"2[0-9]*"}[2m]) > 3
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Nginx latency high (instance {{ $labels.instance }})
          description: "Nginx p99 latency is higher than 3 seconds\n  VALUE = {{ $value }}\n  LABELS = App {{ $labels.app }} in {{ $labels.env }} on {{ $labels.host }} method {{ $labels.method }} status {{ $labels.status }} quantile {{ $labels.quantile }}"

  - name: "physical resources"
    rules:
      - alert: high_load
        expr: node_load1 > 80
        for: 30s
        labels:
          severity: error
        annotations:
          summary: "Instance {{ $labels.instance }} under high load"
          description: "{{ $labels.instance }} of job {{ $labels.job }} is under high load."

      - alert: OutOfMemory
        expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Out of memory (instance {{ $labels.instance }})"
          description: "Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

      - alert: OutOfDiskSpace
        expr: node_filesystem_avail_bytes{mountpoint ="/"} / node_filesystem_size_bytes{mountpoint ="/"} * 100 < 15
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Out of disk space (instance {{ $labels.instance }})"
          description: "Disk is almost full (< 15% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

# not in metrics 
#      - alert: DiskWillFillIn4Hours
#        expr: predict_linear(node_filesystem_free_bytes[1h], 4 * 3600) < 0
#        for: 5m
#        labels:
#          severity: warning
#        annotations:
#          summary: "Disk will fill in 4 hours (instance {{ $labels.instance }})"
#          description: "Disk will fill in 4 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
